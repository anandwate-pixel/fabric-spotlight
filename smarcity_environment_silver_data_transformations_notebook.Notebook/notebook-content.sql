-- Fabric notebook source

-- METADATA ********************

-- META {
-- META   "kernel_info": {
-- META     "name": "synapse_pyspark"
-- META   },
-- META   "dependencies": {
-- META     "lakehouse": {
-- META       "default_lakehouse": "72c73d23-04a5-435b-b0ee-6dd6f6da2a00",
-- META       "default_lakehouse_name": "smartcity_environment_lakehouse_bronze",
-- META       "default_lakehouse_workspace_id": "533b48a0-ffeb-47ef-a6a2-8025527f6dd1",
-- META       "known_lakehouses": [
-- META         {
-- META           "id": "72c73d23-04a5-435b-b0ee-6dd6f6da2a00"
-- META         },
-- META         {
-- META           "id": "e77edd51-6f0f-4266-87ed-1d4600e592e9"
-- META         },
-- META         {
-- META           "id": "a7a84c6e-692e-4fc9-ad61-c2c70417ff30"
-- META         }
-- META       ]
-- META     }
-- META   }
-- META }

-- CELL ********************

-- MAGIC %%pyspark
-- MAGIC from pyspark.sql import functions as F
-- MAGIC from pyspark.sql.window import Window
-- MAGIC from delta.tables import DeltaTable
-- MAGIC 
-- MAGIC # 1. Load Silver tables
-- MAGIC traffic_df = spark.table("smartcity_environment_lakehouse_silver.dbo.trafficapi_kafka_silver")
-- MAGIC weather_df = spark.table("smartcity_environment_lakehouse_silver.dbo.weatherapi_kafka_silver")
-- MAGIC 
-- MAGIC # 2. Normalize city names
-- MAGIC traffic_df = traffic_df.withColumn("city_norm", F.lower(F.col("city")))
-- MAGIC weather_df = weather_df.withColumn("city_norm", F.lower(F.col("city")))
-- MAGIC 
-- MAGIC # 3. Apply mapping dictionary
-- MAGIC city_map = {
-- MAGIC     "gurugram": "gurgaon",
-- MAGIC     "west delhi": "delhi",
-- MAGIC     "connaught place": "connaught place",
-- MAGIC     "new delhi": "new delhi",
-- MAGIC     "noida": "noida"
-- MAGIC }
-- MAGIC for k, v in city_map.items():
-- MAGIC     traffic_df = traffic_df.withColumn("city_norm", F.when(F.col("city_norm") == k, v).otherwise(F.col("city_norm")))
-- MAGIC     weather_df = weather_df.withColumn("city_norm", F.when(F.col("city_norm") == k, v).otherwise(F.col("city_norm")))
-- MAGIC 
-- MAGIC # 4. Round timestamps to nearest 30 minutes
-- MAGIC def round_to_half_hour(col):
-- MAGIC     return F.from_unixtime((F.unix_timestamp(col)/1800).cast("int")*1800)
-- MAGIC 
-- MAGIC traffic_df = traffic_df.withColumn("current_time", round_to_half_hour("current_time"))
-- MAGIC weather_df = weather_df.withColumn("current_time", round_to_half_hour("current_time"))
-- MAGIC 
-- MAGIC # 5. Drop rows with any nulls
-- MAGIC traffic_df = traffic_df.na.drop("any")
-- MAGIC weather_df = weather_df.na.drop("any")
-- MAGIC 
-- MAGIC # 6. Join on city + rounded current_time
-- MAGIC merged_df = (
-- MAGIC     traffic_df.alias("t")
-- MAGIC     .join(weather_df.alias("w"), ["city_norm", "current_time"], "inner")
-- MAGIC     .select(
-- MAGIC         F.col("t.lat").alias("lat"),
-- MAGIC         F.col("t.lon").alias("lon"),
-- MAGIC         F.col("t.city").alias("city"),
-- MAGIC         F.col("current_time"),
-- MAGIC         F.col("w.temp_c"),
-- MAGIC         F.col("w.humidity"),
-- MAGIC         F.col("w.text").alias("condition_text"),
-- MAGIC         F.col("w.wind_kph"),
-- MAGIC         F.col("w.pressure_mb"),
-- MAGIC         F.col("w.precip_mm"),
-- MAGIC         F.col("w.cloud"),
-- MAGIC         F.col("t.congestion"),
-- MAGIC         F.col("t.currentSpeed"),
-- MAGIC         F.col("t.roadClosure"),
-- MAGIC         F.col("w.co").alias("airquality_co"),
-- MAGIC         F.col("w.no2").alias("airquality_no2"),
-- MAGIC         F.col("w.o3").alias("airquality_o3"),
-- MAGIC         F.col("w.so2").alias("airquality_so2"),
-- MAGIC         F.col("w.is_day")
-- MAGIC     )
-- MAGIC )
-- MAGIC 
-- MAGIC # 7. Deduplicate by city + current_time
-- MAGIC deduped_df = merged_df.dropDuplicates(["city","current_time"])
-- MAGIC 
-- MAGIC # 8. Save to Gold table (create if not exists)
-- MAGIC deduped_df.write.format("delta").mode("overwrite").saveAsTable(
-- MAGIC     "smartcity_environment_lakehouse_gold.smartcity_environment_weather_traffic_table"
-- MAGIC )
-- MAGIC 
-- MAGIC # 9. Upsert (merge) into Gold table
-- MAGIC gold_table = DeltaTable.forName(
-- MAGIC     spark, "smartcity_environment_lakehouse_gold.smartcity_environment_weather_traffic_table"
-- MAGIC )
-- MAGIC 
-- MAGIC gold_table.alias("gold").merge(
-- MAGIC     deduped_df.alias("src"),
-- MAGIC     "gold.city = src.city AND gold.current_time = src.current_time"
-- MAGIC ).whenMatchedUpdateAll().whenNotMatchedInsertAll().execute()
-- MAGIC 
-- MAGIC # 10. Preview
-- MAGIC display(deduped_df.limit(50))


-- METADATA ********************

-- META {
-- META   "language": "python",
-- META   "language_group": "synapse_pyspark"
-- META }
